{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d53e0a91",
   "metadata": {},
   "source": [
    "# 1) Install and Verify Dependencies\n",
    "\n",
    "This section installs required packages and checks optional system tools (like `ffmpeg`) for audio decoding backends used by `pydub`.\n",
    "\n",
    "- Core: librosa, tensorflow, scikit-learn, matplotlib, seaborn\n",
    "- Utilities: pydub (fallback loader), resampy (resampling), soundfile\n",
    "- Optional: ffmpeg (system binary) for broader audio format support with pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e3450",
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Optional) Install packages if missing. Uncomment if running in a fresh environment.\n",
    "# %pip install -q librosa tensorflow scikit-learn matplotlib seaborn pydub resampy soundfile\n",
    "\n",
    "import shutil\n",
    "import sys\n",
    "print(\"Python:\", sys.version)\n",
    "print(\"FFmpeg found:\", shutil.which(\"ffmpeg\") is not None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a844be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2) Imports, GPU Check, and Deterministic Seeds\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Reproducibility\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "tf.random.set_seed(SEED)\n",
    "\n",
    "# GPU memory growth (optional)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "if gpus:\n",
    "    try:\n",
    "        for gpu in gpus:\n",
    "            tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(f\"GPUs available: {len(gpus)}; memory growth enabled\")\n",
    "    except Exception as e:\n",
    "        print(\"Could not set memory growth:\", e)\n",
    "else:\n",
    "    print(\"No GPU detected; running on CPU\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1178e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3) Configure Dataset Paths and Target Genres\n",
    "DATASET_PATH = \"data/Data/genres_original\"\n",
    "GENRES = ['blues', 'classical', 'country', 'disco', 'hiphop',\n",
    "          'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "SAMPLE_RATE = 22050\n",
    "DURATION = 30  # seconds\n",
    "\n",
    "# Validate dataset path\n",
    "assert os.path.isdir(DATASET_PATH), f\"Dataset path not found: {DATASET_PATH}\"\n",
    "\n",
    "# Validate genre folders\n",
    "missing = [g for g in GENRES if not os.path.isdir(\n",
    "    os.path.join(DATASET_PATH, g))]\n",
    "if missing:\n",
    "    print(\"Warning: missing genre folders:\", missing)\n",
    "else:\n",
    "    print(\"All target genre folders present\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1f233",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4) Explore Dataset Files\n",
    "from collections import defaultdict\n",
    "\n",
    "per_genre_paths = defaultdict(list)\n",
    "\n",
    "for genre in GENRES:\n",
    "    gpath = os.path.join(DATASET_PATH, genre)\n",
    "    if not os.path.isdir(gpath):\n",
    "        continue\n",
    "    files = sorted([f for f in os.listdir(gpath) if f.lower().endswith(\n",
    "        (\".wav\", \".mp3\", \".flac\", \".ogg\"))])\n",
    "    for f in files[:5]:  # show a few examples\n",
    "        per_genre_paths[genre].append(os.path.join(gpath, f))\n",
    "\n",
    "for genre, items in per_genre_paths.items():\n",
    "    print(f\"{genre} (showing {len(items)} files):\")\n",
    "    for p in items:\n",
    "        print(\"  \", p)\n",
    "    if not items:\n",
    "        print(\"   [No audio files found]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2abe87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5) Robust Audio Loading and Mel-Spectrogram Extraction\n",
    "import warnings\n",
    "\n",
    "\n",
    "def extract_features(file_path, sr=SAMPLE_RATE, duration=DURATION):\n",
    "    \"\"\"\n",
    "    Load audio with multiple fallbacks, pad/trim to fixed duration,\n",
    "    and compute dB-scaled Mel-spectrogram (n_mels=128).\n",
    "    Returns: np.ndarray shape (n_mels, time)\n",
    "    \"\"\"\n",
    "    import numpy as _np\n",
    "    y = None\n",
    "    try:\n",
    "        y, _sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        try:\n",
    "            warnings.filterwarnings('ignore')\n",
    "            y, _sr = librosa.load(\n",
    "                file_path, sr=sr, duration=duration, res_type='kaiser_fast')\n",
    "        except Exception as e2:\n",
    "            print(f\"Second attempt failed: {e2}\")\n",
    "            try:\n",
    "                from pydub import AudioSegment\n",
    "                audio = AudioSegment.from_file(file_path)\n",
    "                samples = _np.array(audio.get_array_of_samples())\n",
    "                if audio.channels == 2:\n",
    "                    samples = samples.reshape((-1, 2)).mean(axis=1)\n",
    "                y = samples.astype(_np.float32) / _np.iinfo(samples.dtype).max\n",
    "                if sr != audio.frame_rate:\n",
    "                    import resampy\n",
    "                    y = resampy.resample(y, audio.frame_rate, sr)\n",
    "            except Exception as e3:\n",
    "                print(f\"All loading methods failed for {file_path}: {e3}\")\n",
    "                y = _np.zeros(sr * duration, dtype=_np.float32)\n",
    "\n",
    "    target_len = sr * duration\n",
    "    if len(y) < target_len:\n",
    "        y = _np.pad(y, (0, target_len - len(y)))\n",
    "    elif len(y) > target_len:\n",
    "        y = y[:target_len]\n",
    "\n",
    "    mel = librosa.feature.melspectrogram(\n",
    "        y=y, sr=sr, n_fft=2048, hop_length=512, n_mels=128)\n",
    "    mel_db = librosa.power_to_db(mel, ref=_np.max)\n",
    "    return mel_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36f4be2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6) Dataset Assembly and Label Encoding\n",
    "from typing import List, Tuple, Dict\n",
    "\n",
    "\n",
    "def prepare_dataset(dataset_path: str, genres: List[str], min_samples_per_class: int | None = None):\n",
    "    \"\"\"\n",
    "    Iterate over genre folders, extract Mel-spectrograms, and encode labels.\n",
    "    Returns: X (N, 128, T), y (N,), label_encoder, samples_per_genre (dict)\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    samples_per_genre: Dict[str, int] = {g: 0 for g in genres}\n",
    "\n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(dataset_path, genre)\n",
    "        if not os.path.isdir(genre_path):\n",
    "            print(f\"Skipping missing genre: {genre}\")\n",
    "            continue\n",
    "        files = [f for f in os.listdir(genre_path) if f.lower().endswith(\n",
    "            (\".wav\", \".mp3\", \".flac\", \".ogg\"))]\n",
    "        for fname in files:\n",
    "            fpath = os.path.join(genre_path, fname)\n",
    "            try:\n",
    "                mel = extract_features(fpath)\n",
    "                features.append(mel)\n",
    "                labels.append(genre)\n",
    "                samples_per_genre[genre] += 1\n",
    "                if min_samples_per_class and samples_per_genre[genre] >= min_samples_per_class:\n",
    "                    break\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing {fpath}: {e}\")\n",
    "\n",
    "    for genre, count in samples_per_genre.items():\n",
    "        print(f\"{genre}: {count} samples\")\n",
    "\n",
    "    X = np.array(features, dtype=np.float32)\n",
    "    le = LabelEncoder()\n",
    "    y = le.fit_transform(labels)\n",
    "    y = np.array(y, dtype=np.int64)\n",
    "    return X, y, le, samples_per_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a134efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7) Data Quality Check and Visualizations\n",
    "\n",
    "def plot_mel_spectrogram(mel_spectrogram, title='Mel Spectrogram'):\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(mel_spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Mel Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def check_data_quality(X: np.ndarray, threshold: float = -60.0):\n",
    "    bad_indices = []\n",
    "    for i, spec in enumerate(X):\n",
    "        if np.mean(spec) < threshold:\n",
    "            bad_indices.append(i)\n",
    "            print(\n",
    "                f\"Warning: Sample {i} may have low quality (mean dB: {np.mean(spec):.2f})\")\n",
    "    if bad_indices:\n",
    "        print(\n",
    "            f\"Found {len(bad_indices)} potentially problematic samples out of {len(X)}\")\n",
    "    else:\n",
    "        print(\"All samples passed quality check.\")\n",
    "    return bad_indices\n",
    "\n",
    "\n",
    "def check_data_balance(y: np.ndarray, label_encoder: LabelEncoder):\n",
    "    class_counts = np.bincount(y)\n",
    "    class_names = label_encoder.classes_\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.bar(class_names, class_counts)\n",
    "    plt.title('Class Distribution')\n",
    "    plt.xlabel('Genre')\n",
    "    plt.ylabel('Number of Samples')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    for name, count in zip(class_names, class_counts):\n",
    "        print(f\"{name}: {count} samples\")\n",
    "\n",
    "    if class_counts.min() > 0 and class_counts.max() / class_counts.min() > 1.5:\n",
    "        print(\"\\nWarning: Data imbalance detected. Consider resampling or using class weights.\")\n",
    "\n",
    "    return class_counts, class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa59894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8) Train/Validation/Test Split and Tensor Reshape\n",
    "\n",
    "def create_train_test_data(X: np.ndarray, y: np.ndarray, test_size: float = 0.2, val_size: float = 0.2):\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=SEED\n",
    "    )\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, stratify=y_train, random_state=SEED\n",
    "    )\n",
    "\n",
    "    # Shape to (N, freq_bins, time_frames, channels)\n",
    "    def _add_channel(a):\n",
    "        return a[..., np.newaxis]\n",
    "\n",
    "    X_train = _add_channel(X_train)\n",
    "    X_val = _add_channel(X_val)\n",
    "    X_test = _add_channel(X_test)\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee1e768d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9) CRNN Model Definition\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dropout, Reshape, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "\n",
    "def create_crnn_model(input_shape, num_classes, learning_rate=8e-4):\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    x = Conv2D(32, (3, 3), padding='same', activation='relu',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.0015))(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), padding='same', activation='relu',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.0015))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.0015))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding='same', activation='relu',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.0015))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    x = Conv2D(256, (3, 3), padding='same', activation='relu',\n",
    "               kernel_regularizer=tf.keras.regularizers.l2(0.002))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((4, 4))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Convert to (batch, time, features) for RNN using a safe reshape\n",
    "    x = tf.keras.layers.Permute((2, 1, 3))(x)  # (batch, time, freq, ch)\n",
    "    x = tf.keras.layers.TimeDistributed(tf.keras.layers.Flatten())(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(128, return_sequences=True,\n",
    "                           recurrent_dropout=0.1,\n",
    "                           recurrent_regularizer=tf.keras.regularizers.l2(0.002)))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Bidirectional(LSTM(128, return_sequences=False,\n",
    "                           recurrent_dropout=0.1,\n",
    "                           recurrent_regularizer=tf.keras.regularizers.l2(0.002)))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    x = Dense(256, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.002))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    x = Dense(128, activation='relu',\n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.002))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    model.compile(optimizer=Adam(learning_rate=learning_rate),\n",
    "                  loss='sparse_categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5b4d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10) Training Utilities: Augmentation, Callbacks, and LR Schedule\n",
    "\n",
    "def train_crnn_model(model, X_train, y_train, X_val=None, y_val=None, X_test=None,\n",
    "                     batch_size=16, epochs=100,\n",
    "                     model_path='crnn_music_genre_model', class_weights=None,\n",
    "                     validation_split=None):\n",
    "    datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "        width_shift_range=0.15,\n",
    "        height_shift_range=0.15,\n",
    "        zoom_range=0.15,\n",
    "        rotation_range=5,\n",
    "        brightness_range=[0.8, 1.2],\n",
    "        fill_mode='constant',\n",
    "        horizontal_flip=False\n",
    "    )\n",
    "\n",
    "    callbacks = [\n",
    "        EarlyStopping(monitor='val_loss', patience=25,\n",
    "                      restore_best_weights=True, verbose=1),\n",
    "        ModelCheckpoint(f'{model_path}_best.keras', monitor='val_accuracy',\n",
    "                        save_best_only=True, mode='max', verbose=1),\n",
    "        ReduceLROnPlateau(monitor='val_loss', factor=0.15,\n",
    "                          patience=5, min_lr=1e-7, verbose=1),\n",
    "        tf.keras.callbacks.TensorBoard(\n",
    "            log_dir=f'./logs/{model_path}', histogram_freq=1, update_freq='epoch')\n",
    "    ]\n",
    "\n",
    "    # Trim spectrogram time dimension to a consistent width\n",
    "    max_T = 259\n",
    "    X_train = X_train[:, :, :max_T, :]\n",
    "    if X_val is not None:\n",
    "        X_val = X_val[:, :, :max_T, :]\n",
    "    if X_test is not None:\n",
    "        X_test = X_test[:, :, :max_T, :]\n",
    "\n",
    "    if X_val is not None and y_val is not None:\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "            steps_per_epoch=max(1, len(X_train) // batch_size),\n",
    "            epochs=epochs,\n",
    "            validation_data=(X_val, y_val),\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "    else:\n",
    "        # Use Keras internal validation split from training data\n",
    "        if not validation_split:\n",
    "            validation_split = 0.2\n",
    "        history = model.fit(\n",
    "            datagen.flow(X_train, y_train, batch_size=batch_size),\n",
    "            steps_per_epoch=max(1, len(X_train) // batch_size),\n",
    "            epochs=epochs,\n",
    "            validation_split=validation_split,\n",
    "            callbacks=callbacks,\n",
    "            class_weight=class_weights,\n",
    "            verbose=1\n",
    "        )\n",
    "\n",
    "    model.save(f'{model_path}_final.keras')\n",
    "    np.save(f'{model_path}_history.npy', history.history)\n",
    "\n",
    "    # Plot training history\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history.get('accuracy', []))\n",
    "    plt.plot(history.history.get('val_accuracy', []))\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history.get('loss', []))\n",
    "    plt.plot(history.history.get('val_loss', []))\n",
    "    plt.title('Model Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend(['Train', 'Validation'])\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{model_path}_training_history.png')\n",
    "    plt.show()\n",
    "\n",
    "    return history, X_train, X_val, X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daf39d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 11) Class Imbalance Handling (Weights and Oversampling)\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.utils import resample\n",
    "\n",
    "\n",
    "def compute_class_weights(y: np.ndarray):\n",
    "    classes = np.unique(y)\n",
    "    weights = compute_class_weight(\n",
    "        class_weight='balanced', classes=classes, y=y)\n",
    "    return {int(c): float(w) for c, w in zip(classes, weights)}\n",
    "\n",
    "\n",
    "def oversample_minority_classes(X: np.ndarray, y: np.ndarray, target_class_count: int | None = None):\n",
    "    if target_class_count is None:\n",
    "        counts = np.bincount(y)\n",
    "        target_class_count = int(counts.max())\n",
    "\n",
    "    X_resampled = []\n",
    "    y_resampled = []\n",
    "    for class_id in np.unique(y):\n",
    "        X_class = X[y == class_id]\n",
    "        y_class = y[y == class_id]\n",
    "        if len(X_class) < target_class_count:\n",
    "            X_r, y_r = resample(\n",
    "                X_class, y_class, replace=True,\n",
    "                n_samples=target_class_count, random_state=SEED\n",
    "            )\n",
    "        else:\n",
    "            X_r, y_r = X_class, y_class\n",
    "        X_resampled.append(X_r)\n",
    "        y_resampled.append(y_r)\n",
    "\n",
    "    X_out = np.concatenate(X_resampled, axis=0)\n",
    "    y_out = np.concatenate(y_resampled, axis=0)\n",
    "    return X_out, y_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c9580a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 12) Model Training and History Plots\n",
    "# Prepare data\n",
    "X, y, label_encoder, samples_per_genre = prepare_dataset(DATASET_PATH, GENRES)\n",
    "print(\"Features shape:\", X.shape, \"Labels shape:\", y.shape)\n",
    "\n",
    "# Quality & balance\n",
    "_ = check_data_quality(X, threshold=-60)\n",
    "_ = check_data_balance(y, label_encoder)\n",
    "\n",
    "# Split\n",
    "X_train, X_val, X_test, y_train, y_val, y_test = create_train_test_data(X, y)\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# Handle imbalance\n",
    "class_weights = compute_class_weights(y)\n",
    "print(\"Class weights:\", class_weights)\n",
    "\n",
    "X_train_bal, y_train_bal = oversample_minority_classes(X_train, y_train)\n",
    "print(\"Balanced train shape:\", X_train_bal.shape)\n",
    "\n",
    "# Build model\n",
    "input_shape = (X_train_bal.shape[1], X_train_bal.shape[2], 1)\n",
    "num_classes = len(np.unique(y))\n",
    "model = create_crnn_model(input_shape, num_classes, learning_rate=8e-4)\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "history, X_train_proc, X_val_proc, X_test_proc = train_crnn_model(\n",
    "    model,\n",
    "    X_train_bal, y_train_bal,\n",
    "    X_val, y_val,\n",
    "    X_test,\n",
    "    batch_size=16,\n",
    "    epochs=150,\n",
    "    model_path='crnn_music_genre_model',\n",
    "    class_weights=class_weights\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f7f772",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13) Evaluation: Metrics and Confusion Matrix\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "def evaluate_model(model, X_test, y_test, label_encoder):\n",
    "    import seaborn as sns\n",
    "    y_pred = model.predict(X_test)\n",
    "    y_pred_cls = np.argmax(y_pred, axis=1)\n",
    "\n",
    "    class_names = label_encoder.classes_\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred_cls, target_names=class_names))\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred_cls)\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "                xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.yticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('confusion_matrix.png')\n",
    "    plt.show()\n",
    "\n",
    "    mis = np.where(y_pred_cls != y_test)[0]\n",
    "    if len(mis) > 0:\n",
    "        print(f\"\\nMisclassified examples ({min(5, len(mis))} shown):\")\n",
    "        for i in range(min(5, len(mis))):\n",
    "            idx = mis[i]\n",
    "            true_label = label_encoder.inverse_transform([y_test[idx]])[0]\n",
    "            pred_label = label_encoder.inverse_transform([y_pred_cls[idx]])[0]\n",
    "            conf = float(np.max(y_pred[idx]) * 100)\n",
    "            print(\n",
    "                f\"Index {idx}: predicted {pred_label} ({conf:.2f}%) but true {true_label}\")\n",
    "\n",
    "\n",
    "# Run evaluation\n",
    "_ = evaluate_model(model, X_test_proc, y_test, label_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17abf501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 14) Save, Load, and Run Inference on New Audio\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "MODEL_BEST = 'crnn_music_genre_model_best.keras'\n",
    "\n",
    "# Example: load best model (if exists) and run inference on a file\n",
    "if os.path.isfile(MODEL_BEST):\n",
    "    best_model = load_model(MODEL_BEST)\n",
    "else:\n",
    "    print(f\"Best model not found at {MODEL_BEST}; using current trained model\")\n",
    "    best_model = model\n",
    "\n",
    "\n",
    "def preprocess_audio_for_inference(filepath: str, max_T: int = 259):\n",
    "    mel = extract_features(filepath)\n",
    "    mel = mel[:, :max_T]\n",
    "    mel = mel[np.newaxis, ..., np.newaxis]  # (1, 128, T, 1)\n",
    "    return mel\n",
    "\n",
    "\n",
    "# Provide your own audio path from the repo, e.g., an MP3 in audio/\n",
    "example_audio = 'audio/OMG - NewJeans.mp3'\n",
    "if os.path.isfile(example_audio):\n",
    "    sample = preprocess_audio_for_inference(example_audio)\n",
    "    probs = best_model.predict(sample)[0]\n",
    "    pred_idx = int(np.argmax(probs))\n",
    "    pred_label = label_encoder.inverse_transform([pred_idx])[0]\n",
    "    print(\n",
    "        f\"Predicted: {pred_label} (confidence {float(np.max(probs))*100:.2f}%)\")\n",
    "else:\n",
    "    print(f\"Example audio not found at {example_audio}; skip demo.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
