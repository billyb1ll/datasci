{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import librosa\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout , Conv2D, MaxPooling2D, Flatten,Conv1D,MaxPooling1D,LSTM\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder  # Make sure this im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = \"data/Data/genres_original\"\n",
    "GENRES = ['blues', 'classical', 'jazz', 'pop', 'rock']\n",
    "SAMPLE_RATE = 22050\n",
    "\n",
    "for dirname, _, filenames in os.walk('data/Data/genres_original'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_features(file_path, sr=22050, duration=30):\n",
    "    \"\"\"\n",
    "    สกัดคุณลักษณะ Mel-spectrogram จากไฟล์เสียง\n",
    "    \n",
    "    Parameters:\n",
    "        file_path (str): เส้นทางไฟล์เสียง\n",
    "        sr (int): อัตราการสุ่มตัวอย่าง\n",
    "        duration (int): ระยะเวลาที่ใช้ (วินาที)\n",
    "        \n",
    "    Returns:\n",
    "        mel_spectrogram (np.array): Mel-spectrogram\n",
    "    \"\"\"\n",
    "    # Ensure numpy is imported at the function level if not available globally\n",
    "    import numpy as np\n",
    "    \n",
    "    try:\n",
    "        # Try the default loading method\n",
    "        y, sr = librosa.load(file_path, sr=sr, duration=duration)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading {file_path}: {e}\")\n",
    "        try:\n",
    "            # Try with audioread backend explicitly\n",
    "            import warnings\n",
    "            warnings.filterwarnings('ignore')\n",
    "            y, sr = librosa.load(file_path, sr=sr, duration=duration, res_type='kaiser_fast')\n",
    "        except Exception as e:\n",
    "            print(f\"Second attempt failed: {e}\")\n",
    "            try:\n",
    "                # Try with pydub as last resort\n",
    "                from pydub import AudioSegment\n",
    "                \n",
    "                audio = AudioSegment.from_file(file_path)\n",
    "                samples = np.array(audio.get_array_of_samples())\n",
    "                # Convert to float32 and normalize\n",
    "                if audio.channels == 2:\n",
    "                    samples = samples.reshape((-1, 2))\n",
    "                    # Take average of both channels\n",
    "                    samples = samples.mean(axis=1)\n",
    "                y = samples.astype(np.float32) / np.iinfo(samples.dtype).max\n",
    "                \n",
    "                if sr != audio.frame_rate:\n",
    "                    # Need to resample\n",
    "                    import resampy\n",
    "                    y = resampy.resample(y, audio.frame_rate, sr)\n",
    "            except Exception as e:\n",
    "                print(f\"All loading methods failed for {file_path}: {e}\")\n",
    "                # Return empty array with correct shape\n",
    "                y = np.zeros(sr * duration)\n",
    "    \n",
    "    # Ensure the audio is the right length\n",
    "    if len(y) < sr * duration:\n",
    "        # Pad if too short\n",
    "        y = np.pad(y, (0, sr * duration - len(y)))\n",
    "    elif len(y) > sr * duration:\n",
    "        # Trim if too long\n",
    "        y = y[:sr * duration]\n",
    "    \n",
    "    # สกัด Mel-spectrogram\n",
    "    mel_spectrogram = librosa.feature.melspectrogram(\n",
    "        y=y, \n",
    "        sr=sr, \n",
    "        n_fft=2048, \n",
    "        hop_length=512, \n",
    "        n_mels=128\n",
    "    )\n",
    "    \n",
    "    # แปลงเป็น Decibel scale\n",
    "    mel_spectrogram = librosa.power_to_db(mel_spectrogram, ref=np.max)\n",
    "    \n",
    "    return mel_spectrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# การโหลดและจัดเตรียมชุดข้อมูล\n",
    "def prepare_dataset(dataset_path, genres):\n",
    "    \"\"\"\n",
    "    เตรียมชุดข้อมูลสำหรับการฝึกฝน\n",
    "    \n",
    "    Parameters:\n",
    "        dataset_path (str): เส้นทางไปยังโฟลเดอร์ที่มีไฟล์เสียง\n",
    "        genres (list): รายการประเภทดนตรีที่ต้องการจำแนก\n",
    "        \n",
    "    Returns:\n",
    "        X (np.array): อาร์เรย์ของคุณลักษณะ\n",
    "        y (np.array): อาร์เรย์ของป้ายกำกับ\n",
    "    \"\"\"\n",
    "    features = []\n",
    "    labels = []\n",
    "    \n",
    "    for genre in genres:\n",
    "        genre_path = os.path.join(dataset_path, genre)\n",
    "        for file_name in os.listdir(genre_path):\n",
    "            if file_name.endswith('.wav') or file_name.endswith('.mp3'):\n",
    "                file_path = os.path.join(genre_path, file_name)\n",
    "                print(f'Extracting features from {file_path}')\n",
    "                mel_spec = extract_features(file_path)\n",
    "                features.append(mel_spec)\n",
    "                labels.append(genre)\n",
    "    \n",
    "    # แปลงป้ายกำกับเป็นตัวเลข\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(labels)\n",
    "    \n",
    "    # แปลงลิสต์เป็น numpy array\n",
    "    X = np.array(features)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y, label_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# สร้างชุดข้อมูลสำหรับการฝึกฝนและทดสอบ\n",
    "def create_train_test_data(X, y, test_size=0.2, val_size=0.2):\n",
    "    \"\"\"\n",
    "    แบ่งข้อมูลเป็นชุดฝึกฝน ตรวจสอบ และทดสอบ\n",
    "    \n",
    "    Parameters:\n",
    "        X (np.array): อาร์เรย์ของคุณลักษณะ\n",
    "        y (np.array): อาร์เรย์ของป้ายกำกับ\n",
    "        test_size (float): สัดส่วนของชุดทดสอบ\n",
    "        val_size (float): สัดส่วนของชุดตรวจสอบ\n",
    "        \n",
    "    Returns:\n",
    "        X_train, X_val, X_test, y_train, y_val, y_test\n",
    "    \"\"\"\n",
    "    # แบ่งข้อมูลออกเป็นชุดฝึกฝนและทดสอบก่อน\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=test_size, stratify=y, random_state=42\n",
    "    )\n",
    "    \n",
    "    # จากชุดฝึกฝน แบ่งออกเป็นชุดฝึกฝนและตรวจสอบ\n",
    "    X_train, X_val, y_train, y_val = train_test_split(\n",
    "        X_train, y_train, test_size=val_size, stratify=y_train, random_state=42\n",
    "    )\n",
    "    \n",
    "    # ปรับรูปร่างข้อมูลให้เหมาะกับ CRNN (samples, time_steps, features, channels)\n",
    "    X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "    X_val = X_val.reshape(X_val.shape[0], X_val.shape[1], X_val.shape[2], 1)\n",
    "    X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "    \n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ฟังก์ชันแสดงตัวอย่าง Mel-spectrogram\n",
    "def plot_mel_spectrogram(mel_spectrogram, title='Mel Spectrogram'):\n",
    "    \"\"\"\n",
    "    แสดง Mel-spectrogram ด้วย matplotlib\n",
    "    \n",
    "    Parameters:\n",
    "        mel_spectrogram (np.array): Mel-spectrogram ที่ต้องการแสดง\n",
    "        title (str): ชื่อกราฟ\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.imshow(mel_spectrogram, aspect='auto', origin='lower', cmap='viridis')\n",
    "    plt.colorbar(format='%+2.0f dB')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Time')\n",
    "    plt.ylabel('Mel Frequency')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset_path = '/home/bill/code/AI/data/Data/genres_original'\n",
    "    genres = ['blues', 'classical', 'country', 'disco', 'hiphop', \n",
    "              'jazz', 'metal', 'pop', 'reggae', 'rock']\n",
    "    \n",
    "    # เตรียมข้อมูล\n",
    "    X, y, label_encoder = prepare_dataset(dataset_path, genres)\n",
    "    print(f\"รูปร่างของคุณลักษณะ: {X.shape}\")\n",
    "    print(f\"รูปร่างของป้ายกำกับ: {y.shape}\")\n",
    "    \n",
    "    # แสดงตัวอย่าง Mel-spectrogram\n",
    "    plot_mel_spectrogram(X[0], title=f'Mel Spectrogram: {label_encoder.inverse_transform([y[0]])[0]}')\n",
    "    \n",
    "    # สร้างชุดข้อมูลฝึกฝน ตรวจสอบ และทดสอบ\n",
    "    X_train, X_val, X_test, y_train, y_val, y_test = create_train_test_data(X, y)\n",
    "    print(f\"รูปร่างของข้อมูลฝึกฝน: {X_train.shape}\")\n",
    "    print(f\"รูปร่างของข้อมูลตรวจสอบ: {X_val.shape}\")\n",
    "    print(f\"รูปร่างของข้อมูลทดสอบ: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, BatchNormalization\n",
    "from tensorflow.keras.layers import Dropout, Reshape, Dense, LSTM, Bidirectional\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
    "\n",
    "def create_crnn_model(input_shape, num_classes):\n",
    "    \"\"\"\n",
    "    สร้างโมเดล CRNN สำหรับการจำแนกดนตรี\n",
    "    \n",
    "    Parameters:\n",
    "        input_shape (tuple): รูปร่างของอินพุต (time_steps, features, channels)\n",
    "        num_classes (int): จำนวนประเภทดนตรี\n",
    "        \n",
    "    Returns:\n",
    "        model (tf.keras.Model): โมเดล CRNN\n",
    "    \"\"\"\n",
    "    # อินพุตเลเยอร์\n",
    "    inputs = Input(shape=input_shape)\n",
    "    \n",
    "    # ส่วน CNN \n",
    "    # ชั้นที่ 1\n",
    "    x = Conv2D(filters=64, kernel_size=(3, 3), padding='same', activation='relu')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # ชั้นที่ 2\n",
    "    x = Conv2D(filters=128, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # ชั้นที่ 3\n",
    "    x = Conv2D(filters=256, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    \n",
    "    # ชั้นที่ 4\n",
    "    x = Conv2D(filters=512, kernel_size=(3, 3), padding='same', activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(4, 4))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # เปลี่ยนรูปร่างสำหรับ RNN\n",
    "    # ทำให้อยู่ในรูปแบบ (time_steps, features)\n",
    "    # ลำดับความสำคัญ: เวลาอยู่ตามแกนความกว้าง (width) และทุกความถี่รวมเป็นคุณลักษณะ\n",
    "    _, height, width, channels = x.shape\n",
    "    x = Reshape((width, height * channels))(x)\n",
    "    \n",
    "    # ส่วน RNN - จับความสัมพันธ์เชิงลำดับตามเวลา\n",
    "    # ใช้ Bidirectional LSTM เพื่อตรวจจับรูปแบบทั้งไปข้างหน้าและย้อนกลับ\n",
    "    x = Bidirectional(LSTM(256, return_sequences=True))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # LSTM ชั้นที่ 2 ไม่ส่งคืนลำดับ แต่ส่งคืนเฉพาะสถานะสุดท้าย\n",
    "    x = Bidirectional(LSTM(256, return_sequences=False))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "    \n",
    "    # ชั้นเชื่อมต่อแบบเต็ม (Fully Connected Layer)\n",
    "    x = Dense(512, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    \n",
    "    # ชั้นเอาต์พุต\n",
    "    outputs = Dense(num_classes, activation='softmax')(x)\n",
    "    \n",
    "    # สร้างโมเดล\n",
    "    model = Model(inputs=inputs, outputs=outputs)\n",
    "    \n",
    "    # คอมไพล์โมเดล\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=0.0001),\n",
    "        loss='sparse_categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "def train_crnn_model(model, X_train, y_train, X_val, y_val, X_test, batch_size=32, epochs=100,model_path='crnn_music_genre_model'):\n",
    "    \"\"\"\n",
    "    ฝึกฝนโมเดล CRNN\n",
    "    \n",
    "    Parameters:\n",
    "        model (tf.keras.Model): โมเดล CRNN\n",
    "        X_train, y_train: ข้อมูลฝึกฝน\n",
    "        X_val, y_val: ข้อมูลตรวจสอบ\n",
    "        X_test: ข้อมูลทดสอบ\n",
    "        batch_size (int): ขนาดของ batch\n",
    "        epochs (int): จำนวนรอบการฝึกฝน\n",
    "        \n",
    "    Returns:\n",
    "        history: ประวัติการฝึกฝน\n",
    "    \"\"\"\n",
    "    # กำหนด callbacks\n",
    "    callbacks = [\n",
    "        # หยุดก่อนกำหนดเมื่อ validation loss ไม่ลดลง\n",
    "        EarlyStopping(\n",
    "            monitor='val_loss',\n",
    "            patience=15,\n",
    "            restore_best_weights=True\n",
    "        ),\n",
    "        # บันทึกโมเดลที่ดีที่สุด\n",
    "        ModelCheckpoint(\n",
    "            'best_crnn_model.h5',\n",
    "            monitor='val_accuracy',\n",
    "            save_best_only=True,\n",
    "            mode='max'\n",
    "        ),\n",
    "        # ลดอัตราการเรียนรู้เมื่อ validation loss ไม่ลดลง\n",
    "        ReduceLROnPlateau(\n",
    "            monitor='val_loss',\n",
    "            factor=0.5,\n",
    "            patience=5,\n",
    "            min_lr=1e-6\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Trim spectrograms to fixed width\n",
    "    X_train = X_train[:, :, :259]  # ตัดความกว้างของ spectrogram\n",
    "    X_val = X_val[:, :, :259]\n",
    "    X_test = X_test[:, :, :259]\n",
    "\n",
    "\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        batch_size=batch_size,\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, y_val),\n",
    "        callbacks=callbacks\n",
    "    )\n",
    "        # บันทึกโมเดลหลังการฝึกฝน\n",
    "    model.save(f'{model_path}_final.keras')\n",
    "    \n",
    "    # บันทึก history เป็นไฟล์ numpy\n",
    "    np.save(f'{model_path}_history.npy', history.history)\n",
    "    \n",
    "    print(f\"โมเดลถูกบันทึกไว้ที่ '{model_path}_final.keras'\")\n",
    "    print(f\"ประวัติการฝึกฝนถูกบันทึกไว้ที่ '{model_path}_history.npy'\")\n",
    "    \n",
    "    return history, X_train, X_val, X_test  # Return modified data for later use\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 259, 1)  # (freq_bins, time_frames, channels)\n",
    "num_classes = 10  # จำนวนประเภทดนตรี\n",
    "model = create_crnn_model(input_shape, num_classes)\n",
    "model.summary()\n",
    "history, X_train_processed, X_val_processed, X_test_processed = train_crnn_model(\n",
    "        model, X_train, y_train, X_val, y_val, X_test, \n",
    "        batch_size=32, epochs=100\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow Environment",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
